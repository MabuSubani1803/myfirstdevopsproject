{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Forest_Fires.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1uKDWOADOI8mg4jPPoxmBGepo7k6Nxh8J\n",
    "\"\"\"\n",
    "\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "forestfire = pd.read_csv('/content/forestfires.csv')\n",
    "forestfire\n",
    "\n",
    "\"\"\"Data Exploration\"\"\"\n",
    "\n",
    "# print shape of dataset with rows and columns\n",
    "print(forestfire.shape)\n",
    "# print top 5 records\n",
    "forestfire.head()\n",
    "\n",
    "\"\"\"Data Exploration\"\"\"\n",
    "\n",
    "# print shape of dataset with rows and columns\n",
    "print(forestfire.shape)\n",
    "# print top 5 records\n",
    "forestfire.head()\n",
    "\n",
    "forestfire.describe()\n",
    "\n",
    "forestfire.info()\n",
    "\n",
    "forestfire.isnull().sum()\n",
    "\n",
    "forestfire.duplicated()\n",
    "\n",
    "forestfire.columns\n",
    "\n",
    "forestfire.drop(columns=['dayfri', 'daymon', 'daysat', 'daysun', 'daythu',\n",
    "       'daytue', 'daywed', 'monthapr', 'monthaug', 'monthdec', 'monthfeb',\n",
    "       'monthjan', 'monthjul', 'monthjun', 'monthmar', 'monthmay', 'monthnov',\n",
    "       'monthoct', 'monthsep'],inplace=True)\n",
    "forestfire\n",
    "\n",
    "# List of Numerical Variables\n",
    "numerical_features=[feature for feature in forestfire.columns if forestfire[feature].dtypes != 'O']\n",
    "\n",
    "print('Number of numerical variables:', len(numerical_features))\n",
    "\n",
    "# Visualize the numerical variables\n",
    "forestfire[numerical_features].head()\n",
    "\n",
    "discrete_feature=[feature for feature in numerical_features if len(forestfire[feature].unique())<25]\n",
    "print('Discrete Variables Count: {}'.format(len(discrete_feature)))\n",
    "\n",
    "continuous_feature=[feature for feature in numerical_features if feature not in discrete_feature]\n",
    "print('Continuous Feature Count {}'.format(len(continuous_feature)))\n",
    "\n",
    "# find categorical variables\n",
    "\n",
    "categorical = [var for var in forestfire.columns if forestfire[var].dtype=='O']\n",
    "\n",
    "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
    "\n",
    "print('The categorical variables are :\\n\\n', categorical)\n",
    "\n",
    "\"\"\"Data Visualization\"\"\"\n",
    "\n",
    "#Importing Libraries seaborn and matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig= plt.figure(figsize=(18, 8))\n",
    "sns.heatmap(forestfire.corr(), annot=True);\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "sns.pairplot(forestfire, hue='size_category')\n",
    "plt.show()\n",
    "\n",
    "ot=forestfire.copy()\n",
    "fig, axes=plt.subplots(7,1,figsize=(14,12),sharex=False,sharey=False)\n",
    "sns.boxplot(x='FFMC',data=ot,palette='crest',ax=axes[0])\n",
    "sns.boxplot(x='DMC',data=ot,palette='crest',ax=axes[1])\n",
    "sns.boxplot(x='DC',data=ot,palette='crest',ax=axes[2])\n",
    "sns.boxplot(x='ISI',data=ot,palette='crest',ax=axes[3])\n",
    "sns.boxplot(x='temp',data=ot,palette='crest',ax=axes[4])\n",
    "sns.boxplot(x='RH',data=ot,palette='crest',ax=axes[5])\n",
    "sns.boxplot(x='area',data=ot,palette='crest',ax=axes[6])\n",
    "plt.tight_layout(pad=2.0)\n",
    "\n",
    "#forestfireAfter Log-Transformation\n",
    "for feature in continuous_feature:\n",
    "    data=forestfire.copy()\n",
    "    data[feature]=np.log(data[feature])\n",
    "    data.boxplot(column=feature)\n",
    "    plt.ylabel(feature)\n",
    "    plt.title(feature)\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"Data Pre-Processing\"\"\"\n",
    "\n",
    "continuous_feature=[feature for feature in forestfire.columns if forestfire[feature].dtype!='O']\n",
    "print('Continuous Feature Count {}'.format(len(continuous_feature)))\n",
    "\n",
    "forestfire[continuous_feature]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "df_standard_scaled = forestfire.copy()\n",
    "features = df_standard_scaled[continuous_feature]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_standard_scaled[continuous_feature] = scaler.fit_transform(features.values)\n",
    "df_standard_scaled.head()\n",
    "\n",
    "\"\"\"Label Encoding\"\"\"\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "forestfire[\"day\"] = le.fit_transform(forestfire[\"day\"])\n",
    "forestfire[\"month\"] = le.fit_transform(forestfire[\"month\"])\n",
    "forestfire[\"size_category\"] = le.fit_transform(forestfire[\"size_category\"])\n",
    "\n",
    "forestfire\n",
    "\n",
    "\"\"\"Test Train Split With Imbalanced Dataset\"\"\"\n",
    "\n",
    "x = forestfire.drop('size_category',axis=1)\n",
    "y = forestfire[['size_category']]\n",
    "\n",
    "# Splitting data into test data and train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=3)\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "keras. __version__\n",
    "\n",
    "forestfire\n",
    "#assigning predictor variables to x and response variable to y\n",
    "x = forestfire.drop('size_category',axis=1)\n",
    "y = forestfire[['size_category']]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.20, random_state=42)\n",
    "\n",
    "scaler_train = StandardScaler()\n",
    "scaler_test = StandardScaler()\n",
    "\n",
    "x_train_scaled = scaler_train.fit_transform(x_train) # scaling train data -- predictor\n",
    "x_test_scaled  = scaler_test.fit_transform(x_test) # scaling test data -- predictor\n",
    "\n",
    "print(x_train_scaled.shape)\n",
    "print(x_test_scaled.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "def toFindBestParams(x_train, y_train, x_test, y_test):\n",
    "    #print(y_test.shape)\n",
    "    #sys.exit()\n",
    "\n",
    "    #defining list of hyperparameters\n",
    "    batch_size_list = [5 , 10 , 15 , 20]\n",
    "    epoch_list      = [5 , 10 , 50 , 100]\n",
    "\n",
    "    # initializing the trials\n",
    "    for batch_trial in batch_size_list:\n",
    "        for epochs_trial in epoch_list:\n",
    "\n",
    "            # create ANN model\n",
    "            model = Sequential()\n",
    "            # Defining the first layer of the model\n",
    "            model.add(Dense(units=50, input_dim=x_train.shape[1], kernel_initializer='normal', activation='tanh'))\n",
    "\n",
    "            # Defining the Second layer of the model\n",
    "            model.add(Dense(units=6, kernel_initializer='normal', activation='tanh'))\n",
    "\n",
    "            # The output neuron is a single fully connected node\n",
    "            # Since we will be predicting a single number\n",
    "            model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "\n",
    "            # Compiling the model\n",
    "            model.compile(loss='binary_crossentropy', optimizer='adam',  metrics=['accuracy'])\n",
    "\n",
    "            # Fitting the ANN to the Training set\n",
    "            model_trained = model.fit(x_train, y_train ,batch_size = batch_trial, epochs = epochs_trial, verbose=0)\n",
    "\n",
    "             # Fetching the accuracy of the training\n",
    "            Accuracy_train = model_trained.history['accuracy'][-1]\n",
    "\n",
    "            # printing the results of the current iteration\n",
    "            print('batch_size:', batch_trial,'-', 'epochs:',epochs_trial, 'Accuracy:',Accuracy_train)\n",
    "\n",
    "# Calling the function\n",
    "toFindBestParams(x_train, y_train, x_test, y_test)\n",
    "\n",
    "ann = Sequential()\n",
    "\n",
    "ann.add(Dense(units=15,activation='relu'))\n",
    "ann.add(Dense(units=10,activation='relu'))\n",
    "ann.add(Dense(units=1,activation='sigmoid'))\n",
    "ann.compile(optimizer='Adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = ann.fit(x_train, y_train, validation_split=0.33, batch_size = 10, epochs = 100)\n",
    "\n",
    "history.history.keys()\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# generating predictions for test data\n",
    "y_predict_test = ann.predict(x_test)\n",
    "\n",
    "# creating table with test price & predicted price for test\n",
    "test_prediction = pd.DataFrame()\n",
    "test_prediction['Test_Actual'] = y_test.size_category\n",
    "test_prediction['Test_Probability'] = y_predict_test\n",
    "def probToBinary(varProb):\n",
    "    if varProb >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# converting the probability of target variable to binary class of test data\n",
    "test_prediction['Test_Predicted'] = test_prediction['Test_Probability'].apply(probToBinary)\n",
    "print(test_prediction.shape)\n",
    "test_prediction.head(10)\n",
    "\n",
    "# generating predictions for train data\n",
    "y_predict_train = ann.predict(x_train)\n",
    "\n",
    "# creating table with test price & predicted price for test\n",
    "train_prediction = pd.DataFrame()\n",
    "train_prediction['Train_Actual'] = y_train.size_category\n",
    "train_prediction['Train_Probability'] = y_predict_train\n",
    "train_prediction['Train_Predicted'] = train_prediction['Train_Probability'].apply(probToBinary)\n",
    "print(train_prediction.shape)\n",
    "train_prediction.head(10)\n",
    "\n",
    "# plot confusion matrix to describe the performance of classifier.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_df=confusion_matrix(test_prediction['Test_Actual'], test_prediction['Test_Predicted'])\n",
    "class_label = [\"No\", \"Yes\"]\n",
    "df_cm = pd.DataFrame(cm_df, index = class_label, columns = class_label)\n",
    "sns.heatmap(df_cm, annot = True, fmt = \"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import roc_curve,auc,roc_auc_score\n",
    "fpr, tpr, thresholds = roc_curve(test_prediction['Test_Actual'], test_prediction['Test_Predicted'])\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, linewidth=2, color='red')\n",
    "plt.plot([0,1], [0,1], 'k--' )\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for SVM Classifier using Linear Kernel for Predicting Size_category')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.show()\n",
    "ROC_AUC = roc_auc_score(test_prediction['Test_Actual'], test_prediction['Test_Predicted'])\n",
    "print('ROC AUC : {:.4f}'.format(ROC_AUC))\n",
    "\n",
    "# plot histogram of predicted probabilities\n",
    "# adjust the font size\n",
    "plt.rcParams['font.size'] = 12\n",
    "# plot histogram with 10 bins\n",
    "plt.hist(test_prediction['Test_Probability'], bins = 10)\n",
    "# set the title of predicted probabilities\n",
    "plt.title('Histogram of predicted probabilities of Forest Burned Area')\n",
    "# set the x-axis limit\n",
    "plt.xlim(0,1)\n",
    "# set the title\n",
    "plt.xlabel('Predicted probabilities of Forest Burned Area')\n",
    "plt.ylabel('Frequency')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
